# Titanic-Data-Analysis---Flames-25---Summer-Training
ğŸš¢ Titanic Survival Analysis & Classification â€“ EDA + KNN + Decision Tree
This project is developed as a part of my Summer Training under the guidance of Ms. Gaurika Dhingra Mam on the Flames'25 platform, as a proud member of the Angaar Batch. The goal of this project is to explore, analyze, and predict passenger survival on the Titanic using Python, including Exploratory Data Analysis (EDA) and two Machine Learning models â€“ K-Nearest Neighbors (KNN) and Decision Tree Classifier.

ğŸ“ Dataset
The dataset used is a cleaned version of the Titanic passenger data and includes the following features:

Survived (Target variable)

Pclass (Passenger class)

Sex

Age

Fare

Siblings/Spouses Aboard

Parents/Children Aboard

ğŸ§  Project Objectives
Perform descriptive statistics and visualization to understand survival trends.

Analyze how features like age, gender, fare, class, and family aboard influenced survival.

Build and compare classification models using KNN and Decision Tree.

Derive key insights based on data patterns and model performance.

ğŸ“Š Exploratory Data Analysis (EDA)
The project includes:

Count plots, histograms, scatter plots, box plots, and heatmaps using Seaborn and Matplotlib

Central tendency and dispersion metrics (mean, median, std dev, etc.)

Outlier detection using IQR method

Survival analysis based on:

Gender

Passenger class

Fare

Age

Family members aboard

ğŸ” Key Insights:
Females had a significantly higher survival rate.

1st class passengers were more likely to survive.

Fare positively impacted survival chances.

Younger passengers and those with 1â€“2 family members aboard had better chances.

ğŸ¤– Machine Learning Models
Two supervised learning algorithms were used:

âœ… K-Nearest Neighbors (KNN)
Simple algorithm that classifies based on nearest data points.

Suitable for smaller, clean datasets.

Accuracy Achieved: ~XX.XX% (replace with your value)

ğŸŒ³ Decision Tree Classifier
Works well with both numeric and categorical features.

Provides clear decision paths.

Accuracy Achieved: ~XX.XX% (replace with your value)

âš–ï¸ Conclusion:
After comparing accuracy scores, Decision Tree showed better performance on this dataset.

It handled mixed data types and imbalances more effectively.

ğŸ›  Tools & Technologies
Python 3

Pandas, NumPy

Matplotlib, Seaborn

scikit-learn

Prakhar Gupta
B.Tech CSE | Lovely Professional University
ğŸ“ Summer Training | Flames'25 â€“ Angaar Batch
ğŸ§‘â€ğŸ« Mentor: Ms. Gaurika Dhingra Mam
ğŸ“§ Email: prakhargupta00123456@gmail.com
ğŸ”— LinkedIn: https://www.linkedin.com/in/prakhar-gupta-366449280/

â­ Support
If you liked this project, donâ€™t forget to give it a â­ on GitHub!
Your support means a lot and encourages me to keep building and learning.
